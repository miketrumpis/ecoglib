{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Methods: Bootstrap and Jackknife"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "ecoglib implements samplers for two types of resampling methods: :py:class:`ecoglib.estimation.resampling.Bootstrap` and :py:class:`ecoglib.estimation.resampling.Jackknife`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'\n",
    "os.environ['NUMEXP_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(108774)\n",
    "import scipy.stats.distributions as dists\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import ecoglib.estimation.resampling as resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple bootstrapping\n",
    "\n",
    "Both resampling schemes are *nonparameteric* methods to infer the distribution of samples, or a statistic of samples. This is in contrast to a parametric estimator analysis that pre-supposes the sampling/statistic distribution. \n",
    "\n",
    "**Parametric analysis**\n",
    "\n",
    "A simple parametric assumption would be a sample $\\{x\\}_{i}$ of $N$ independent and identically distributed (iid) variates from a friendly distribution with (*finite!*) mean $\\mu$ and variance $\\sigma^{2}$. It would follow that the sample mean estimator $\\hat{\\mu}=\\sum_{i}(N^{-1}x_{i})$ is a variate with mean $\\mu$ and variance $\\sigma^{2}/N$. In other words, the standard error (SE) of the mean (SEM) is $\\sigma /\\sqrt{N}$ (which itself has an unbiased estimate using the sample variance estimator $\\hat{\\sigma}^{2}/(N-1)$). The distribution of the sample mean divided by the sample SEM is t-distributed in the interval around the true mean. The t-distribution has very heavy tails for low sample sizes, reflecting lower precision confidence with less information. For n=10 samples, the t-distribution is ~15% wider than a Normal, but for n=20 it is ~7% wider.\n",
    "\n",
    "**Nonparametric (bootstrap) analysis**\n",
    "\n",
    "[Bootstrap](https://en.wikipedia.org/wiki/Bootstrapping_%28statistics%29) tries to infer the sample distribution by creates many point estimates (usually >>100) from synthetic samples. Specifically, bootstrap drawns $N$ times from the original $N$ points with replacement to emulate repeating an experiment to draw $N$ *new* points. The quantiles of the $P$ pseudo estimates are then used to infer statistics of the actual sample distribution. Bootstrap is also most reliable for symmetric distributions with finite variance. Similar to the Normal approximation for CIs, Bootstrap percentiles are also too narrow by about $\\sqrt{(N-1)/N}$, which is somewhat noticeable for small N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 13   # sample size\n",
    "P = 1000  # resamples\n",
    "# normal samples mean of 5, stdev 2\n",
    "sigma_sq = 4\n",
    "mu = 5\n",
    "sample_dist = dists.norm(loc=mu, scale=sigma_sq ** 0.5)\n",
    "x_norm = sample_dist.rvs(size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = resampling.Bootstrap(x_norm, P, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(precision=2, suppress=True):\n",
    "    print('Real sample:', np.sort(x_norm))\n",
    "    for n, samp in enumerate(bs.sample()):\n",
    "        print('Fake sample {}:'.format(n + 1), np.sort(samp))\n",
    "        if n == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can draw all bootstrap samples and look at the apparent distribution of the mean estimator compared to the actual distribution of the mean estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bs = bs.all_samples(estimator=np.mean)  # pseudo-samples from distribution\n",
    "mean_est = np.mean(mean_bs)  # mean of bootstrap estimators\n",
    "sample_mean = np.mean(x_norm)  # plain sample mean\n",
    "mean_dist = dists.norm(mu, (sigma_sq / N) ** 0.5)  # actual distribution\n",
    "x = np.linspace(3, 7, 100)\n",
    "px = mean_dist.pdf(x)\n",
    "actual_CI = mean_dist.ppf([0.025, 0.975])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrap samples are only as good as the original sample. With a fairly low $N$, we'd expect a poor mean estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "_ = plt.hist(mean_bs, bins='auto', density=True, histtype='step')\n",
    "_ = plt.plot(x, px)\n",
    "_ = plt.axvline(sample_mean, color='k', label='sample mean')\n",
    "_ = plt.axvline(mean_est, color='r', label='mean est.')\n",
    "_ = plt.axvline(actual_CI[0], color='gray', ls='--')\n",
    "_ = plt.axvline(actual_CI[1], color='gray', ls='--', label='Actual CI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the $P$ estimator replicates, we can compare the nonparametric quantiles of the mean to the parametric SEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = x_norm.mean()\n",
    "# shift the actual CI to be centered around the sample mean\n",
    "shift_CI = actual_CI - 5 + sample_mean\n",
    "# unbiased sem estimator\n",
    "parametric_sem = x_norm.std() / np.sqrt(N - 1)\n",
    "parametric_CI = dists.t.ppf([0.025, 0.975], N - 1) * parametric_sem + sample_mean\n",
    "bootstrap_CI = np.percentile(mean_bs, [2.5, 97.5])\n",
    "\n",
    "plt.figure()\n",
    "_ = plt.hist(mean_bs, bins='auto', density=True, histtype='step')\n",
    "_ = plt.axvline(sample_mean, color='k', label='sample mean')\n",
    "_ = plt.axvline(mean_est, color='r', label='mean est.')\n",
    "_ = plt.axvline(shift_CI[0], color='gray', ls='--')\n",
    "_ = plt.axvline(shift_CI[1], color='gray', ls='--', label='mean est. +/- actual CI')\n",
    "_ = plt.axvline(parametric_CI[0], color='darkorange', ls='--')\n",
    "_ = plt.axvline(parametric_CI[1], color='darkorange', ls='--', label='+/- parametric CI')\n",
    "_ = plt.axvline(bootstrap_CI[0], color='yellowgreen', ls='--')\n",
    "_ = plt.axvline(bootstrap_CI[1], color='yellowgreen', ls='--', label='+/- bootstrap CI')\n",
    "plt.legend(loc=(1.1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a simple Bootstraper\n",
    "\n",
    "For convenience, the alpha-confidence interval (or the Bootstrapped standard error) can be requested from the Bootstrap estimator method. This returns\n",
    "\n",
    "* plain sample estimate $\\theta(x)$\n",
    "* mean of bootstrapped estimates: $E\\{\\theta(x^{*})\\}$\n",
    "* CI or SD of the distribution of the estimated statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc with CI\n",
    "sample_mean, bootstrap_mean, ci = bs.estimate(np.mean, ci=0.95)\n",
    "print('Bootstrap 95% confidence: T[x] {}, E[T(x*)] {}, CI T[x]: {}'.format(sample_mean, bootstrap_mean, ci))\n",
    "\n",
    "# Calc with SE\n",
    "sample_mean, bootstrap_mean, se = bs.estimate(np.mean, ci='se')\n",
    "print('Bootstrap 95% confidence: T[x] {}, E[T(x*)] {}, SE T[x]: {}'.format(sample_mean, bootstrap_mean, se))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even more simply (without creating a Bootstrap object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, bs_mu, ci = resampling.Bootstrap.bootstrap_estimate(x_norm, P, np.mean, ci=0.95)\n",
    "print(mu, bs_mu, ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jackknife\n",
    "\n",
    "The [jackknife](https://en.wikipedia.org/wiki/Jackknife_resampling) predates bootstrap as a resampling method. It uses a leave-one-out resampling scheme, rather than resampling with replacement, which means that it can create only (up to) $N$ replicate estimators. For the sample $X_{i}$ (set notation omitted for simplicity), each jackknifed sample is\n",
    "\n",
    "$X_{-i}=(x_1,\\dots,x_{i-1},x_{i+1},\\dots,x_{N})$\n",
    "\n",
    "\n",
    "The jackknife is used to find the mean and error of not-necessarily-simple estimators $\\theta(X)$. However, it is often warned that the jackknife should be avoided for nonlinear, non-smooth estimators, such as median and correlation coefficient. The jackknife estimate of the mean is defined as\n",
    "\n",
    "$\\hat{\\theta}_{jn}=\\frac{1}{N}\\sum_i \\theta(X_{-i})$\n",
    "\n",
    "The jackknife does have the advantage of correcting biased estimators (to the leading $1/N$ order of its Taylor expansion). For an estimator $\\theta(X)$ that is biased, we can form jackknife *pseudovalues* from the estimator $\\theta_{-i}$ applied to each jackknife sample:\n",
    "\n",
    "$\\tilde{\\theta}_{-i}=N\\bar{\\theta}-(N-1)\\theta_{-i}$\n",
    "\n",
    "(where $\\bar{\\theta}$ is estimated from the *entire* sample). The average of the pseudovalues, which is $N\\bar{\\theta}-(N-1)\\hat{\\theta}_{jn}$, is a bias-corrected version of the estimator $\\theta$.\n",
    "\n",
    "The jackknife standard error is defined two ways. The basic jackknife estimator variance is based on jackknifed estimators $\\theta_{-i}$\n",
    "\n",
    "$SE_{1}=\\sqrt{\\frac{N-1}{N}\\sum_{i}(\\theta_{-i}-\\hat{\\theta}_{jn})^2}$\n",
    "\n",
    "When using pseudovalues, the jackknife SE is\n",
    "\n",
    "$SE_{2}=\\sqrt{\\left(N(N-1)\\right)^{-1}\\sum_{i}(\\tilde{\\theta}_{-i}-\\langle \\tilde{\\theta} \\rangle)^{2}}$\n",
    "\n",
    "where $\\langle \\rangle$ notation denotes the sample mean of pseudovalues.\n",
    "\n",
    "### Bias example: sample variance\n",
    "The maximum likelihood variance estimator is $N^{-1}\\sum_{i}(x_{i}-\\bar{x})^{2}$, which has a famous bias of $-\\sigma^{2}/n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svar(x):\n",
    "    return np.mean((x - np.mean(x)) ** 2)\n",
    "\n",
    "N = 30   # sample size\n",
    "# normal samples mean of 5, stdev 2\n",
    "sigma_sq = 4\n",
    "mu = 5\n",
    "sample_dist = dists.norm(loc=mu, scale=sigma_sq ** 0.5)\n",
    "x_norm = sample_dist.rvs(size=N)\n",
    "\n",
    "S2 = svar(x_norm)\n",
    "\n",
    "jn = resampling.Jackknife(x_norm, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``Jackknife`` object can be used to estimate the bias of ``svar``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jn_bias = jn.bias(svar)\n",
    "known_bias = -sigma_sq / N\n",
    "print('Jackknife bias: {} (actual bias {})'.format(jn_bias, known_bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jackknife estimate can be made with or without bias correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ML estimator:', S2)\n",
    "print('JN estimator:', jn.estimate(svar, correct_bias=False))\n",
    "print('JN bias corrected:', jn.estimate(svar, correct_bias=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the variance estimator itself has error, which is fairly high compared to the bias. The error can be computed directly (jackknife variance), or returned at the same time as the mean estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Jackknife SE:', jn.variance(svar) ** 0.5)\n",
    "jn_mean, jn_se = jn.estimate(svar, se=True, correct_bias=True)\n",
    "print('Jackknife est and SE:', jn_mean, jn_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More common use: optimization confidence intervals\n",
    "\n",
    "Bootstrap is usually used for complex sampling distributions. For example, we can get a confidence interval for parameters that are derived from optimization problems. We can demonstrate this using ordinary least squares (OLS), which again has an easy to compare parametric analysis. (Again, the bootstrap would normally be used for a more complicated distribution, e.g. for optimizing a nonlinear least squares problem.)\n",
    "\n",
    "Here we have imagined observations of a dependent variable $y$ that linearly varies with the independent variable $x$ with a factor of 1.7. The observations have independent zero mean error with 30% variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(55)\n",
    "e = np.random.randn(55) * (0.3 ** 0.5)\n",
    "y = 1.7 * x + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('IV')\n",
    "plt.ylabel('DV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit an OLS model (slope & intercept) using [statsmodels](https://www.statsmodels.org/dev/user-guide.html#regression-and-linear-models). The size of the confidence intervals here are based on parametric analysis and, interestingly, *only* depend on the independent variable (and not the observations at all!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_fm = sm.OLS(y, np.c_[np.ones_like(x), x]).fit()\n",
    "ols_fm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the summary states, the 95% CI for the intercept marks it as not necessarily non-zero. The 95% CI slope is near the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_fm.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on parametric analysis, the predicted fit has a confidence interval that depends on two factors:\n",
    "\n",
    "1. The error \"scale\": the residual sum of squares (``ols_fm.fm_ssr``) divided by the \"residual degrees of freedom\" (``ols_fm.df_resid``: N - size-of-model). \n",
    "1. The sample size (which affects the standard errors of the parameters)\n",
    "\n",
    "The intercept and slope parameters are t-distributed with scales like: $s\\operatorname{diag}(R^{T}R)^{-1}$, where $s$ is scale and $R$ is the regressor matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict from the model for 100 points\n",
    "xm = np.linspace(x.min(), x.max(), 100)\n",
    "pred = ols_fm.get_prediction(np.c_[np.ones_like(xm), xm])\n",
    "pframe = pred.summary_frame(alpha=0.05)\n",
    "ym = pframe.mean\n",
    "ym_lo = pframe.mean_ci_lower\n",
    "ym_hi = pframe.mean_ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xm = np.linspace(x.min(), x.max(), 100)\n",
    "ym = ols_fm.predict(np.c_[np.ones_like(xm), xm])\n",
    "plt.figure()\n",
    "plt.scatter(x, y, color='k', label='data')\n",
    "plt.plot(xm, ym, color='r', label='predicted mean')\n",
    "plt.plot(xm, np.c_[ym_lo, ym_hi], color='slategray', ls='--', label='95% CI for mean')\n",
    "plt.xlabel('IV')\n",
    "plt.ylabel('DV')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get nonparametric confidence intervals, we can bootstrap the OLS fit and check the quantiles of the resulting optimizations. First, define an estimator function that returns optimization parameters. The estimator [resamples *residuals*](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)#Resampling_residuals) from the original OLS fit (**note: the resampled array(s) need to be first argument(s) of an estimator function**). The resampled residuals are added to the OLS mean response to simulate a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapped_residual_ols(e, x, ym):\n",
    "    \"\"\"\n",
    "    Estimate OLS with bootstrapped residuals.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    e: ndarray\n",
    "        Sample of residuals\n",
    "    x: ndarray\n",
    "        Independent variable\n",
    "    ym: ndarray\n",
    "        Predicted mean response (from full sample)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    params: ndarray\n",
    "        OLS coefficients\n",
    "    \n",
    "    \"\"\"\n",
    "    fm = sm.OLS(ym + e, np.c_[np.ones_like(x), x]).fit()\n",
    "    return fm.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a bootstrapper that resamples the OLS residuals. Use the ``e_args`` parameter to specify \"extra\" arguments: the independent variables and the fitted means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS mean values\n",
    "ym = ols_fm.fittedvalues\n",
    "# OLS residuals\n",
    "err = ols_fm.resid\n",
    "\n",
    "bootstrapper = resampling.Bootstrap(err, 1000)\n",
    "fits = np.array([p for p in bootstrapper.sample(estimator=bootstrapped_residual_ols, e_args=(x, ym))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average fit and the bootstrapped CI are pretty close to the parametric CI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mn = fits.mean(axis=0)\n",
    "p_lo, p_hi = np.percentile(fits, [2.5, 97.5], axis=0)\n",
    "print('Slope BS: {:.3f} ({:.3f} - {:.3f} 95% CI)'.format(p_mn[1], p_lo[1], p_hi[1]))\n",
    "print('Intercept BS: {:.3f} ({:.3f} - {:.3f} 95% CI)'.format(p_mn[0], p_lo[0], p_hi[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take these bootstrapped fits to make a CI for the predicted trend. Create a curve for each bootstrap fit and then find the quantiles of these vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xm * fits[:, 1, None] + fits[:, 0, None]\n",
    "ym_lo_bs, ym_hi_bs = np.percentile(predictions, [2.5, 97.5], axis=0)\n",
    "ym_bs = predictions.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xm = np.linspace(x.min(), x.max(), 100)\n",
    "plt.figure()\n",
    "plt.scatter(x, y, color='k', label='data')\n",
    "plt.plot(xm, ym_bs, color='r', label='BS mean')\n",
    "plt.plot(xm, np.c_[ym_lo_bs, ym_hi_bs], color='slategray', ls='--', label='BS 95% CI')\n",
    "plt.xlabel('IV')\n",
    "plt.ylabel('DV')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing estimates in parallel\n",
    "\n",
    "Resampling methods can be resource intensive for any but the most trivial estimators, but the repeated function calls can be done independently on multiple processes. **Due to the overhead involved in creating new processes, going parallel would only make sense for costly estimation functions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, spinning up processes to parallelize the simple mean takes longer (on some architectures) than running all resamples on a single process: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from ecogdata.parallel.mproc import parallel_context\n",
    "\n",
    "n_jobs = max(2, parallel_context.cpu_count() // 2)\n",
    "\n",
    "# reuse the normal distribution\n",
    "N = int(1e6)\n",
    "x_norm = sample_dist.rvs(size=N)\n",
    "\n",
    "# run in a single process\n",
    "t1 = time()\n",
    "mu_est = resampling.Bootstrap.bootstrap_estimate(x_norm, 100, np.mean, n_jobs=1)[1]\n",
    "tc = time() - t1\n",
    "print('mu estimate: {} ({} sec)'.format(mu_est, tc))\n",
    "\n",
    "# run in 6 processes\n",
    "t1 = time()\n",
    "mu_est = resampling.Bootstrap.bootstrap_estimate(x_norm, 100, np.mean, n_jobs=n_jobs)[1]\n",
    "tc = time() - t1\n",
    "print('mu estimate: {} ({} sec, {} jobs)'.format(mu_est, tc, n_jobs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heavy computation time is simulated here with the \"sleep\" function.\n",
    "\n",
    "**A note about the bizarre syntax:**\n",
    "\n",
    "Multiprocessing works differently in Unix (using \"fork\") and Windows (using \"spawn\"), and this affects the ability to parallelize functions defined in the notebook.\n",
    "\n",
    "A function \"slow_mean\" is defined two ways here. If the multiprocessing startup is spawn mode, then the function is written to a temporary auxiliary module and imported. After importing, the temp file is deleted. If we're forking, then the method text is given to \"exec\" to literally execute the code in the string.\n",
    "\n",
    "These gymnastics are only required for the slightly contrived scenario where a method is defined within the notebook. As seen in the previous cell, externally defined methods can be split without the weird steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_mean_def = \"\"\"\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def slow_mean(x):\n",
    "    mu = x.mean()\n",
    "    sleep(0.05)\n",
    "    return mu\n",
    "\"\"\"\n",
    "\n",
    "forking = parallel_context.context_name == 'fork'\n",
    "\n",
    "# If forking, then define the method on this notebook\n",
    "# Else, do some extra-module work-around\n",
    "if forking:\n",
    "    exec(slow_mean_def)\n",
    "else:\n",
    "    try:\n",
    "        with open('temp_module.py', 'w') as f:\n",
    "            f.write(slow_mean_def)\n",
    "        from temp_module import slow_mean\n",
    "    except:\n",
    "        raise\n",
    "\n",
    "\n",
    "# reuse the normal distribution\n",
    "N = int(1e6)\n",
    "x_norm = sample_dist.rvs(size=N)\n",
    "\n",
    "# run in a single process\n",
    "t1 = time()\n",
    "mu_est = resampling.Bootstrap.bootstrap_estimate(x_norm, 100, slow_mean, n_jobs=1)[1]\n",
    "tc = time() - t1\n",
    "print('mu estimate: {} ({} sec)'.format(mu_est, tc))\n",
    "\n",
    "# Run parallel in spawn/forkserver mode\n",
    "\n",
    "# run in multiple processes\n",
    "t1 = time()\n",
    "mu_est = resampling.Bootstrap.bootstrap_estimate(x_norm, 100, slow_mean, n_jobs=n_jobs)[1]\n",
    "tc = time() - t1\n",
    "print('mu estimate: {} ({} sec, {} jobs)'.format(mu_est, tc, n_jobs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting resampled data\n",
    "\n",
    "The Bootstrap/Jackknife objects can also return the resampled data when estimator is left blank. This is **not** generally accelerated with multiple jobs (you will get a warning if n_jobs > 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuse the normal distribution\n",
    "N = int(1e5)\n",
    "x_norm = sample_dist.rvs(size=N)\n",
    "\n",
    "t1 = time()\n",
    "bs = resampling.Bootstrap(x_norm, 100, n_jobs=1)\n",
    "all_samps1 = bs.all_samples()\n",
    "tc = time() - t1\n",
    "print('serial collect: {} sec'.format(tc))\n",
    "\n",
    "t1 = time()\n",
    "bs = resampling.Bootstrap(x_norm, 100, n_jobs=6)\n",
    "all_samps2 = bs.all_samples()\n",
    "tc = time() - t1\n",
    "print('para collect: {} sec'.format(tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All samples returned: type {} length {}'.format(type(all_samps1), len(all_samps1)))\n",
    "print('First sample:', all_samps1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not forking:\n",
    "    import os\n",
    "    if os.path.exists('temp_module.py'):\n",
    "        os.unlink('temp_module.py')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
